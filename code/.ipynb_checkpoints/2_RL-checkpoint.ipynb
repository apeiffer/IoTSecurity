{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Analysis Using Reinforcement Learning\n",
    "## Spring 2022: Shaoyu Pei, Avery Peiffer\n",
    "\n",
    "## Advisor: Dr. Mai Abdelhakim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 2: Applying Reinforcement Learning to the Problem\n",
    "If you have not already read through and tested out the network setup, please take some time to do so. It will provide you with the necessary background to understand the problem.\n",
    "\n",
    "The purpose of this notebook is to implement a reinforcement learning algorithm using our network environment code. This allows us to train reinforcement learning algorithms. We modified [Laura D'Arcy's GraphRLnx repository](https://github.com/lauradarcy/graphRLnx) to create this class.\n",
    "\n",
    "Please refer to the `tutorials/` folder for an overview of reinforcement learning and Q-learning. Essentially, we wish for our algorithm to learn the most trustworthy path(s) from the source to the destination. A trustworthy path is one that is unlikely to be corrupted from past examples. We start by sending packets through the network randomly; we then use a function to see if the transmission was 'corrupted' in the way that we have previously defined it. We also take into consideration the number of hops the path takes. We adjust our incentive structure accordingly and, over time, the algorithm will learn what paths are optimal.\n",
    "\n",
    "Our model makes the assumption that there is one reinforcement learning controller that is overseeing the entire process. Additionally, we wish to acknowledge the action and state spaces that make up our reinforcement learning space. The state space represents the possible list of states that the algorithm can take in a given time step. In this case, it is defined as the possible nodes that can be visited along a path from the source to destination node. Likewise, the action space represents the possible actions that can be taken from the given state. For this model, the action space is defined as the nodes that are neighboring the current node and that have not already been visited along the current path (this helps avoid cycles and infinite loops)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you get any errors due to packages not being installed, please add them to the cell below. We might have not encountered these errors due to already having those packages installed on our computers for other courses/projects/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym in c:\\users\\avery peiffer\\anaconda3_new\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\avery peiffer\\anaconda3_new\\lib\\site-packages (from gym) (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\avery peiffer\\anaconda3_new\\lib\\site-packages (from gym) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import scipy.signal\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we incorporate everything from the first notebook into a `graphRL` class. This class uses the `gym` environment template, which allows for training of RL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graphRL(gym.Env):\n",
    "    \n",
    "    # Add random edges to the graph until it is a complete graph (more detail in previous notebook)\n",
    "    def random_edge(self):\n",
    "        edges = list(self.graph.edges)\n",
    "        nonedges = list(nx.non_edges(self.graph))\n",
    "        if len(edges) > 0:\n",
    "            chosen_edge = random.choice(edges)\n",
    "            chosen_nonedge = random.choice([x for x in nonedges if chosen_edge[0] == x[0] or chosen_edge[0] == x[1]])\n",
    "        else:\n",
    "            chosen_nonedge = random.choice(nonedges)\n",
    "        self.graph.add_edge(chosen_nonedge[0], chosen_nonedge[1])\n",
    "        \n",
    "    # Determine if a path is corrupted based on the attack probabilities of the nodes that make it up\n",
    "    # (more detail in previous notebook)\n",
    "    def is_corrupted(self, path, verbose=False): \n",
    "        for node in path:\n",
    "            attack_prob = self.devices[node].attack_prob\n",
    "            attacked = random.uniform(0,1) < attack_prob\n",
    "            if attacked:\n",
    "                if verbose:\n",
    "                    print('Node = ', node)\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def __init__(self, fname=None, network_size=10, edge_prob=1, percent_mal=0, attack_probs=[0, 0]):\n",
    "        self.devices = []\n",
    "        self.mal_nodes = []\n",
    "        \n",
    "        class device:\n",
    "            pass\n",
    "\n",
    "        # Read in a custom environment from a file and create the graph that way\n",
    "        if fname != None:\n",
    "            with open(fname) as f:\n",
    "                lines = [line.rstrip() for line in f]\n",
    "\n",
    "                self.network_size = int(lines[0])\n",
    "                self.src = 0\n",
    "                self.dst = self.network_size - 1\n",
    "                \n",
    "                edges = [eval(x) for x in lines[1:-1]]\n",
    "                self.graph = nx.Graph()\n",
    "                self.graph.add_nodes_from(list(range(self.network_size)))\n",
    "                self.graph.add_edges_from(edges)\n",
    "                \n",
    "                attack_probs = [float(x) for x in lines[-1].split(',')]\n",
    "                \n",
    "                nodes = list(range(0, self.network_size))\n",
    "                \n",
    "                for node, prob in zip(nodes, attack_probs):\n",
    "                    a = device()\n",
    "                    a.node = node\n",
    "                    a.attack_prob = prob\n",
    "                    \n",
    "                    if prob > 0:\n",
    "                        self.mal_nodes.append(node)\n",
    "                        a.mal = True\n",
    "                    \n",
    "                    else:\n",
    "                        a.mal = False\n",
    "                        \n",
    "                    self.devices.append(a)\n",
    "        \n",
    "        # Create a random graph based on a set of parameters\n",
    "        else:\n",
    "            self.network_size = network_size\n",
    "            self.src = 0\n",
    "            self.dst = network_size - 1\n",
    "\n",
    "            self.graph = nx.gnp_random_graph(network_size, edge_prob)\n",
    "            while not nx.is_connected(self.graph):\n",
    "                self.random_edge()\n",
    "\n",
    "            num_mal = network_size * percent_mal\n",
    "\n",
    "            while num_mal > 0:\n",
    "                rand = np.random.randint(0, network_size)           \n",
    "                if rand != src and rand != dst and rand not in self.mal_nodes:\n",
    "                    self.mal_nodes.append(rand)\n",
    "                    num_mal -= 1\n",
    "\n",
    "            nodes = list(range(0, network_size))\n",
    "\n",
    "            for node in nodes:\n",
    "                a = device()\n",
    "                a.node = node\n",
    "\n",
    "                if node in self.mal_nodes:\n",
    "                    a.mal = True\n",
    "                    a.attack_prob = np.random.uniform(attack_probs[0], attack_probs[1])\n",
    "                else:\n",
    "                    a.mal = False\n",
    "                    a.attack_prob = 0\n",
    "\n",
    "                self.devices.append(a)\n",
    "            \n",
    "        self.num_actions = self.network_size\n",
    "        self.num_states  = self.network_size\n",
    "            \n",
    "        self.action_space = spaces.Discrete(self.num_actions)                   \n",
    "        self.observation_space = spaces.Discrete(self.num_states)\n",
    "\n",
    "    # Draw the graph\n",
    "    def render(self):\n",
    "        nx.draw(self.graph, with_labels=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of the graphRL class and render it. As a reminder of our convention, the source node is always Node 0 and the destination node is the highest numbered node. Additionally, we print out all of the nodes and whether they are malicious. This will help us confirm that our algorithm is learning to avoid the malicious nodes. By visual inspection, we can also confirm that our algorithm is learning the shortest paths from source to destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 is NOT malicious.\n",
      "Node 1 is NOT malicious.\n",
      "Node 2 is NOT malicious.\n",
      "Node 3 IS malicious. Attack probability is 0.64.\n",
      "Node 4 is NOT malicious.\n",
      "Node 5 IS malicious. Attack probability is 0.85.\n",
      "Node 6 is NOT malicious.\n",
      "Node 7 is NOT malicious.\n",
      "Node 8 is NOT malicious.\n",
      "Node 9 is NOT malicious.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# env = graphRL(network_size=10, edge_prob=0.1, percent_mal=0.4, attack_probs=[0.3, 0.8])\n",
    "env = graphRL('./env/env1.txt')\n",
    "\n",
    "for a in env.devices:\n",
    "    if a.mal:\n",
    "        print(f'Node {a.node} IS malicious. Attack probability is {a.attack_prob:.2f}.')\n",
    "    else:\n",
    "        print(f'Node {a.node} is NOT malicious.')\n",
    "        \n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some hyperparameters we introduce when we move to a RL environment:\n",
    "* `corrupted_path_penalty` refers to the penalty our algorithm incurs when it takes a path that is corrupted.\n",
    "* `dead_end_penalty` refers to the penalty our algorithm incurs when it encounters a dead-end node. We don't need to consider this node for future pathfinding, so we put an enormous penalty on it.\n",
    "* `training_iterations` refers to the number of times we will try to find a path from the source to the destination. Too few iterations will lead to underfitting; too many will lead to overfitting.\n",
    "\n",
    "The other hyperparameters are used for the Q-learning algorithm (definitions used from the [RL tutorial source](https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/)):\n",
    "* `alpha` is the learning rate (0 < $\\alpha$ <= 1). This captures the extent to which the Q-values are updated from one training iteration.\n",
    "* `gamma` is the discount factor (0 < $\\gamma$ <= 1). $\\gamma$ determines how much importance we want to give to future rewards. A lower $\\gamma$ makes our algorithm consider immediate rewards more, while a higher $\\gamma$ captures a long-term effective reward.\n",
    "* `epsilon` is the degree (0 < $\\epsilon$ <= 1) to which we want to explore the action space (i.e. pick a random value) or exploit our learned Q-values. A lower $\\epsilon$ will result in more penalties during training because we are more often picking new, unexplored paths. A higher $\\epsilon$ will result in fewer penalties during training but may lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros([env.num_states, env.num_actions])\n",
    "\n",
    "training_iterations = 10000\n",
    "corrupted_path_penalty = 10\n",
    "clean_path_reward = corrupted_path_penalty / 10 # The clean path reward should probably not be equal to the corrupted path penalty\n",
    "dead_end_penalty = 1000 # Continue working on this \n",
    "# Node: don't want this to be np.inf because it will fail in some edge cases (since invalid neighbors are np.inf)\n",
    "\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "epsilon = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some notes about this cell, because it is the most complicated cell in the notebook:\n",
    "* We are trying to find paths from the source to the destination, and we go one node at a time. Think of the current state as the node we are currently at. The possible actions we can choose from are the other nodes that we can visit from this node (so, its neighbors). However, this is at odds with how we define the Q-table, where all actions are technically \"valid\" from each state. For this reason, we keep a `valid_neighbors` array to reference when we select an action. If a node is a dead end, it will have no valid neighbors and we can stop the training iteration. \n",
    "* When we are finding paths from the source to the destination, we don't want to visit the same node twice (this is called a cycle and can easily lead to infinite loops). We use the `VISITED` flag and `visit_arr` to mark whether we've visited a node in the current pathfinding iteration. This also helps us when we look at the `valid_neighbors` of a node. \n",
    "* As stated above, `epsilon` represents the degree to which we randomly explore the action space. We want to decrease the value of `epsilon` as we train our algorithm to limit the amount that we explore the action space, because it becomes redundant. This is the purpose of the `epsilon_decay` function. We have defined it such that it linearly decreases from the initial value of `epsilon` to 0 over the training iterations, but alternative definitions could be more effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISITED = -1\n",
    "\n",
    "# For plotting metrics\n",
    "all_epochs = []\n",
    "all_penalties = []\n",
    "\n",
    "# Linear function to represent how epsilon should decrease as we go through training iterations\n",
    "def epsilon_decay(x):\n",
    "    return epsilon - epsilon*x/training_iterations\n",
    "\n",
    "# Number of training iterations\n",
    "for i in range(1, training_iterations+1):\n",
    "    total_penalty = 0\n",
    "    path = []\n",
    "    eps = epsilon_decay(i) * epsilon\n",
    "    state = env.src\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    visit_arr = np.zeros(env.network_size)\n",
    "    \n",
    "    while not done:\n",
    "        path.append(state)\n",
    "        dead_end = True\n",
    "        visit_arr[state] = VISITED # Shows that we have visited a node\n",
    "        \n",
    "        valid_neighbors = list(env.graph.neighbors(state)) # These are the valid possible actions\n",
    "        \n",
    "        # Check to see if the node is a dead end (if there are any valid neighbors, they have been visited already)\n",
    "        for neighbor in valid_neighbors:\n",
    "            if visit_arr[neighbor] != VISITED:\n",
    "                dead_end = False\n",
    "        \n",
    "        # This node is a dead end, so we put a giant penalty on it so we don't go to it again in future iterations\n",
    "        if dead_end:\n",
    "            q_table[:, state] = -dead_end_penalty \n",
    "            done = True\n",
    "\n",
    "        # The node is not a dead end, so we continue trying to find paths to the destination\n",
    "        else:  \n",
    "            # Explore the action space by picking a random action\n",
    "            if random.uniform(0, 1) < eps:\n",
    "                action = env.action_space.sample()\n",
    "                \n",
    "                # Make sure the action is valid by referencing the valid neighbors and visited arrays\n",
    "                while action not in valid_neighbors or visit_arr[action] == VISITED:\n",
    "                    action = env.action_space.sample()\n",
    "            \n",
    "            # Exploit learned values by selecting the best action from the current state based on our Q-table\n",
    "            else:\n",
    "                slc = q_table[state]\n",
    "                action = np.argmax(slc)               \n",
    "\n",
    "                # Make sure the action is valid by referencing the valid neighbors and visited arrays\n",
    "                while action not in valid_neighbors or visit_arr[action] == VISITED:\n",
    "                    slc[action] = -np.Inf\n",
    "                    action = np.argmax(slc)                    \n",
    "    \n",
    "            # Now, we've finally selected an action. \n",
    "            # We can take the step and update the Q-table according to the algorithm.            \n",
    "            next_state = action\n",
    "            state = next_state\n",
    "\n",
    "            if state == env.dst:\n",
    "                path.append(state)\n",
    "                done = True\n",
    "                \n",
    "            total_penalty += 1\n",
    "    \n",
    "    # Print out the path we took.\n",
    "    # If we got to the destination, determine if that path was corrupted. Update the reward accordingly\n",
    "    if dead_end == True:\n",
    "        print(f'Path taken = {path}. Encountered a dead end.')\n",
    "    else:\n",
    "        print(f'Path taken = {path}.')\n",
    "        \n",
    "        if env.is_corrupted(path):\n",
    "            # The path is corrupted, but our algorithm doesn't know what node is the cause. \n",
    "            # So, we penalize all of the nodes. Over time, the nodes that are actually corrupted will be\n",
    "            # penalized more often than the nodes that aren't.\n",
    "            total_penalty += corrupted_path_penalty\n",
    "            print(f'This path was corrupted.')\n",
    "    \n",
    "        else:\n",
    "            total_penalty -= clean_path_reward\n",
    "        \n",
    "        # The path[1:len(path)-2] is a way of not penalizing the source or destination nodes, since we\n",
    "        # assume that those two can't be corrupted.\n",
    "        for node in path[1:len(path)-2]:\n",
    "            q_table[:, node] -= total_penalty / len(path)\n",
    "            \n",
    "    all_epochs.append(i)\n",
    "    all_penalties.append(total_penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the training is finished, we can print out the Q table and try to visually confirm that our algorithm has learned the optimal paths. The rows represent the current state, and the columns represent the possible actions from that state. We should see higher values for the actions that lead to clean, shorter paths. Likewise, we should see lower values for actions that result in a corrupted path. Additionally, we should see `-np.inf` for actions that aren't possible from the current state (not neighboring), and `-dead_end_penalty` for actions that result in a dead end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1       2       3       4       5       6       7       8    9\n",
      "0 -inf -inf -1005.0 -1021.5 -1000.0 -1020.0 -1000.0 -1000.0 -1000.0 -inf\n",
      "1 -inf -inf    -inf -1021.5 -1000.0 -1020.0 -1000.0 -1000.0 -1000.0  0.0\n",
      "2 -inf  0.0 -1005.0 -1021.5 -1000.0 -1020.0 -1000.0 -1000.0 -1000.0  0.0\n",
      "3 -inf  0.0 -1005.0 -1021.5 -1000.0 -1020.0 -1000.0 -1000.0 -1000.0  0.0\n",
      "4  0.0  0.0 -1005.0 -1021.5 -1000.0 -1020.0 -1000.0 -1000.0 -1000.0  0.0\n",
      "5 -inf  0.0 -1005.0 -1021.5 -1000.0 -1020.0 -1000.0 -1000.0 -1000.0  0.0\n",
      "6  0.0  0.0 -1005.0 -1021.5 -1000.0 -1020.0 -1000.0 -1000.0 -1000.0  0.0\n",
      "7  0.0  0.0 -1005.0 -1021.5 -1000.0 -1020.0 -1000.0 -1000.0 -1000.0  0.0\n",
      "8  0.0  0.0 -1005.0 -1021.5 -1000.0 -1020.0 -1000.0 -1000.0 -1000.0  0.0\n",
      "9  0.0  0.0 -1005.0 -1021.5 -1000.0 -1020.0 -1000.0 -1000.0 -1000.0  0.0\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(q_table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do a more formal verification of the results. This code uses some of our training code to rerun the algorithm and find what it has determined to be the most efficient, safest paths through the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after 100 episodes:\n",
      "Average hops per episode: 2.0\n",
      "Average penalties per episode: 1.0\n"
     ]
    }
   ],
   "source": [
    "total_hops, total_penalties = 0, 0\n",
    "episodes = 100\n",
    "\n",
    "for _ in range(episodes):\n",
    "    path = []\n",
    "    hops, penalties = 0, 0\n",
    "    state = env.src\n",
    "    visit_arr = np.zeros(env.network_size)\n",
    "        \n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        hops += 1\n",
    "        path.append(state)\n",
    "        dead_end = True\n",
    "        visit_arr[state] = VISITED\n",
    "        \n",
    "        valid_neighbors = list(env.graph.neighbors(state))\n",
    "\n",
    "        for neighbor in valid_neighbors:\n",
    "            if visit_arr[neighbor] != VISITED:\n",
    "                dead_end = False\n",
    "\n",
    "        if dead_end:\n",
    "            total_penalties += 1\n",
    "            done = True\n",
    "        \n",
    "        else:\n",
    "            action = np.argmax(q_table[state])\n",
    "            state = action\n",
    "        \n",
    "        if state == env.dst:\n",
    "            done = True\n",
    "        \n",
    "    if env.is_corrupted(path):\n",
    "        total_penalties += 1\n",
    "    \n",
    "    total_hops += hops\n",
    "    \n",
    "print(f\"Results after {episodes} episodes:\")\n",
    "print(f\"Average hops per episode: {total_hops / episodes}\")\n",
    "print(f\"Average penalties per episode: {total_penalties / episodes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
